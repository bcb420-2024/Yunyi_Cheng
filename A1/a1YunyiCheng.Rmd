---
title: "A1_YunyiCheng"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
date: "2024-02-10"
name: Yunyi Cheng 
csl: a1Nature.csl
bibliography: a1References.bib
bibliography-style: plain
editor_options: 
  markdown: 
    wrap: 45
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

In this notebook, we will be preprocessing a
GEO dataset for further analysis. This
notebook was developed by *Yunyi Cheng* and
runs under Docker image in the BCB420 GitHub
repository.

```{r install and load packages, include=FALSE}
# Loading necessary packages

# Define the list of packages to be used
packages <- c("purrr", "GEOquery", "readr", "dplyr", "biomaRt", "reshape2", "ggplot2",
              "edgeR", "limma", "hgnc", "Biobase", "BiocGenerics", "grateful")

# Function to check if each package is installed and load it, or install it if it's not already installed
install_and_load <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}

# Apply the function to each package
invisible(sapply(packages, install_and_load))
```

### 1.1 Brief introduction of the study

This analysis is informed by recent findings
on sex-dependent gene expression changes in
Parkinson's disease(PD) [@Tranchevent2023].
They highlight PD as a heterogeneous disorder
where biological sex significantly influences
symptom profiles, with males typically having
higher disease incidence and muscle rigidity,
while females more often present with
disabling tremors. The molecular mechanisms
behind these sex-dependent differences remain
largely unknown.

To address this, the authors conducted a
meta-analysis of brain transcriptomics data
from case/control studies, identifying both
sex-specific alterations (changes observed in
only one sex) and sex-dimorphic changes
(changes in both sexes but in opposite
directions). They further explored these
changes through systems-level pathway and
network analyses, which unveiled significant
sex differences in mitochondrial pathways and
highlighted specific regulatory factors.
These factors' activity changes could explain
the observed network alterations through gene
regulatory cascades. The study also utilized
single-cell expression data analyses to
confirm the main pathway-level changes
identified in bulk transcriptomics data.

## 2. Data Cleaning and HUGO Mapping

### 2.1 Download Dataset

```{r create cache and download dataset}
# Create a 'geoCache' directory in the current working directory to 
# avoid re-downloading the data each time we run the notebook
cacheDir <- file.path(getwd(), "geoCache")
if (!dir.exists(cacheDir)) {
  dir.create(cacheDir)
}

# GEO accession number
gseID <- "GSE168496"

# Download and read the GEO series
gse <- GEOquery::getGEO(gseID, destdir=cacheDir, GSEMatrix =TRUE, getGPL=FALSE)

# Extract the instance of GSE series since gse is a list of length 1
if (is.list(gse)) {
  gse <- gse[[1]]
}

# Create the full path to the local file
localFilePath <- file.path(
  cacheDir, "GSE168496_all_samples_preprocessed_data.tsv.gz")

# Check if the file already exists before downloading
if (!file.exists(localFilePath)) {
  # Download the file only if it doesn't already exist in the cache directory
  GEOquery::getGEOSuppFiles(gseID, makeDirectory = FALSE, baseDir = cacheDir)
}

# Proceed to check if the file exists and read it
if (file.exists(localFilePath)) {
  # Read the gzipped TSV file into a data frame
  rawData <- readr::read_tsv(localFilePath)
  print(head(rawData))
} else {
  stop("The dataset file was not successfully downloaded or found.")
}
```

### 2.2 Preprocess Dataset

#### 2.2.1 Change Column Names to GSM numbers

As we can see the column names of `rawData`
are not very informative about the
experiment. Note that each column name
corresponds to one GEO sample, thus we will
change the column names to GEO Sample Numbers
(GSM), which uniquely identify samples that
were used in an experiment.

```{r change row names of rawData to GSM numbers}
# Create a vector of the new column names based on the GSM numbers
gsmNumbers <- c("GSM5144785", "GSM5144786", "GSM5144787", "GSM5144788", 
                "GSM5144789", "GSM5144790", "GSM5144791", "GSM5144792", 
                "GSM5144793", "GSM5144794", "GSM5144795", "GSM5144796", 
                "GSM5144797", "GSM5144798", "GSM5144799", "GSM5144800")


# Ensure the length of 'gsmNumbers' matches num column in 'rawData'
# Skip the first column which contains gene identifiers
if (length(gsmNumbers) == ncol(rawData) - 1) {
  # Assign the new column names to 'rawData'
  colnames(rawData)[-1] <- gsmNumbers
} else {
  stop("The number of GSM numbers 
       does not match the number of columns in the dataframe.")
}

# Check the new column names
colnames(rawData)
```

#### 2.2.2 Map ENSEMBL IDs to HUGO Symbols

To map ENSEMBL IDs (which start with "ENST")
to HUGO gene symbols, we can use the biomaRt
package in R to query the ENSEMBL database.
But first of all, we need to check for
invalid ENSEMBL IDs in `rawData` and remove
them.

```{r filter for invalid ENSEMBL IDs}
# Function to filter out invalid ENSEMBL IDs
filterInvalidEnsemblIDs <- function(rawData) {
  # Define the regex pattern for ENSEMBL transcript IDs
  pattern <- "^ENST\\d{11}(\\.\\d+)?$"
  
  # Find which IDs are valid
  validIDs <- sapply(rawData$id, function(id) grepl(pattern, id))
  
  # Count invalid IDs
  numInvalidIDs <- sum(!validIDs)
  
  # Print the number of invalid IDs
  message("There are ", numInvalidIDs, " invalid ENSEMBL IDs.")
  
  # Filter out invalid IDs
  validData <- rawData[validIDs, ]
  
  return(validData)
}

# Apply the function to remove invalid entries and get the filtered data
filteredData <- filterInvalidEnsemblIDs(rawData)
```

Now we can map ENSEMBL IDs to HUGO gene
symbols.

```{r map to HUGO gene symbols}
# Use biomaRt to map ENSEMBL IDs to HUGO symbols
mapEnsemblToHugo <- function(filteredData) {
  ensembl <- biomaRt::useMart("ensembl", dataset = "hsapiens_gene_ensembl")
  ensemblIds <- filteredData$id
  getSymbols <- biomaRt::getBM(attributes = c('ensembl_transcript_id_version', 
                                              'hgnc_symbol'),
                                filters = 'ensembl_transcript_id_version',
                                values = ensemblIds,
                                mart = ensembl)
  # Merge the symbols back into the filteredData
  filteredData <- merge(filteredData, getSymbols, 
                        by.x = 'id', by.y = 'ensembl_transcript_id_version',
                        all.x = TRUE)
  return(filteredData)
}

# Map ENSEMBL IDs to HUGO symbols
filteredDataWithSymbols <- mapEnsemblToHugo(filteredData)

# Reformat filteredDataWithSymbols
filteredDataWithSymbols <- filteredDataWithSymbols %>%
  dplyr::rename(ensembl_id = id) %>%
  dplyr::select(ensembl_id, hgnc_symbol, everything())

# Identify unmapped data
unmappedData <- filteredDataWithSymbols[
  is.na(filteredDataWithSymbols$hgnc_symbol), ]

# Display number of the unmapped ENSEMBL ids
message("There are ", nrow(unmappedData), " unmapped ENSEMBL IDs.")

# Remove unmapped rows
filteredDataWithSymbols <- 
  filteredDataWithSymbols[!is.na(filteredDataWithSymbols$hgnc_symbol), ]

# Remove the 'ensembl_id' column
filteredDataWithSymbols <- 
  filteredDataWithSymbols %>% dplyr::select(-ensembl_id)

# Check if there are unmapped rows remain
any(is.na(filteredDataWithSymbols$hgnc_symbol))
```

#### 2.2.3 Clean Dataset

Data cleaning has always been controversial.
As supported by these two papers,
[@Neely2012][@Gough2014], we often discover
new stuff when focusing on such outliers.
After reading several papers on whether to
remove outliers, I decided to keep the data
cleaning minimal, which means I only remove
data points if I am very confident it is
generated from errors in the experiment.

According to the study[@Tranchevent2023], the
dataset provided is already pre-cleaned by
removal of samples from conditions other than
idiopathic Parkinson's Disease (PD) and
healthy controls, removal of low-quality
genetic probes, and probes/transcripts with
zero variance.

Nonetheless, we will double-check for missing
or incorrect values and remove them.

```{r check and remove missing incorrect value}

# Filter out the rows where hgnc_symbol is an empty string
filteredDataWithSymbols <- filteredDataWithSymbols %>% 
  dplyr::filter(hgnc_symbol != '')

# Check for negative values
print(paste("There are", 
            sum(filteredDataWithSymbols[, -1] < 0), "negative values."))
negativeValues <- apply(
  filteredDataWithSymbols[, -1], 1, function(x) any(x < 0))

# Remove rows with negative values
filteredDataWithSymbols <- filteredDataWithSymbols[!negativeValues, ]

# Check for missing values
missingValues <- is.na(filteredDataWithSymbols[, -1])
print(paste("There are", sum(missingValues), "missing values."))

# Remove rows missing values
filteredDataWithSymbols <- 
  filteredDataWithSymbols[rowSums(missingValues) == 0, ]

# Check if there are any NA values in the df after removing rows
anyNA(filteredDataWithSymbols)
```

There are non-unique gene symbols which can
be problematic because it can skew the
analysis and interpretation of the results.
To solve this, I decided to aggregate the
expression values by summing them since there
are notably amount of zeros.

```{r aggregate the expression values}
# Aggregate the expression values by summing them for each HUGO symbol
aggregatedData <- filteredDataWithSymbols %>% 
  dplyr::group_by(hgnc_symbol) %>% 
  dplyr::summarise(
    across(everything(), ~ sum(.x, na.rm = TRUE)), .groups = 'drop') %>%
  as.data.frame()
```

### 2.3 Preprocess Metadata for Future Analysis

We now have the dataset mapped to HUGO
symbols, and we want to curate the metadata
for future analysis. Many metadata are the
same across the samples, so we only want to
keep the different characteristics among the
samples.

```{r get metadata from GSM}
getMetadataFromGSM <- function(gsm) {
  # Construct the path to the cached file
  localFilePath <- file.path(cacheDir, paste0(gsm, ".rda"))
  
  # Check if the file exists locally
  if (file.exists(localFilePath)) {
    # Load the local GSM data
    load(localFilePath)
  } else {
    # Fetch the GSM data from GEO and save it locally
    gsmData <- GEOquery::getGEO(gsm, AnnotGPL=FALSE)
    save(gsmData, file = localFilePath)
  }
  
  # Extract the 'characteristics_ch1' field
  characteristics <- gsmData@header$characteristics_ch1
  
  # Initialize an empty list to store the parsed metadata
  metadataList <- list()
  
  # Define the regex pattern for post-mortem delay 
  # (used for special preprocessing)
  pmDelayPattern <- "(\\d+):(\\d{2}):(\\d{2})"
  
  for (char in characteristics) {
    # Split the string by ':' and ' ' to separate the key from the value
    charParts <- strsplit(char, ":\\s+", fixed = FALSE)
    
    # If the characteristic is 'post-mortem delay', apply regex to format
    if (grepl("post-mortem delay", char, ignore.case = TRUE)) {
      pmDelayMatch <- regmatches(char, regexec(pmDelayPattern, char))
      if (length(pmDelayMatch[[1]]) > 1) {  # If a match was found
        metadataList[["post-mortem delay"]] <- pmDelayMatch[[1]][2]
      } else {
        metadataList[["post-mortem delay"]] <- NA  # No valid format found
      }
    } else {
      # For other characteristics, proceed as normal
      if (length(charParts[[1]]) > 1) {
        key <- charParts[[1]][1]
        value <- charParts[[1]][2]
        metadataList[[key]] <- value
      }
    }
  }
  
  # Return the list of metadata as a named vector
  return(unlist(metadataList))
}

# Retrieve and store metadata for each GSM
metadataList <- lapply(gsmNumbers, getMetadataFromGSM)

# Combine all metadata into a single data frame
metadataDf <- do.call(rbind, metadataList)

# Add GSM numbers as a new column
metadataDf <- cbind(GSM = gsmNumbers, metadataDf)

# Display metadataDf
print(head(metadataDf))
```

```{r make sure metadataDf is a data frame}
if (!is.data.frame(metadataDf)) {
  metadataDf <- as.data.frame(metadataDf)
}
is.data.frame(metadataDf)
write.csv(metadataDf, "metadataDf.csv")
```

Since GSM numbers as row names are not very
informative, we can combine information from
metadata to specify the condition of sample
for future merging.

```{r add combinedInfo to metadata}
metadataDf$combinedInfo <- apply(metadataDf, 1, function(x) {
  # Abbreviate the disease state and gender for conciseness
  diseaseAbbrev <- 
    ifelse(x['disease state'] == 'Non-demented control', 'Ctrl', 'PD')
  genderAbbrev <- 
    substr(x['gender'], 1, 1) # 'Male' -> 'M', 'Female' -> 'F'
  
  # Combine the GSM number with the abbreviated disease state and gender
  paste0(x['GSM'], "_", diseaseAbbrev, "_", genderAbbrev)
})

```

```{r Merge the metadata with the expression data}
# Transpose filteredDataWithSymbols for merging
longData <- reshape2::melt(filteredDataWithSymbols, 
                           id.vars = 'hgnc_symbol', 
                           variable.name = 'GSM', 
                           value.name = 'Expression')

# Merge the expression data with metadata, ensuring to include the combinedInfo
mergedData <- merge(longData, metadataDf, by = 'GSM')

# Ensure that categorical data is treated appropriately
mergedData$`disease state` <- as.factor(mergedData$`disease state`)

```

### 2.4 Assess Dataset

Now we have cleaned the dataset, mapped it to
HUGO symbols and combined it with metadata,
we can perform overall statistical analysis
on the dataset.

```{r compute overview statistics}
# Compute overview statistics by gender and disease state
overviewStatsByGenderAndDisease <- mergedData %>%
  dplyr::group_by(gender, `disease state`) %>%
  dplyr::summarise(
    Mean_Expression = mean(Expression, na.rm = TRUE),
    SD_Expression = sd(Expression, na.rm = TRUE),
    Median_Expression = median(Expression, na.rm = TRUE),
    IQR_Expression = IQR(Expression, na.rm = TRUE),
    .groups = 'drop' # Drop the grouping structure afterwards
  )

# Display the results
print(overviewStatsByGenderAndDisease)
```

We can see that there are some notable
differences between female and male, as well
as between control and Parkinson's samples.
We will further explore the dataset after
normalization.

## 3. Normalization

### 3.1 Reformat Dataset

Before normalization, we need to reformat the
data frame so that it has 16 numeric columns
(for 16 samples) and unique HUGO symbols as
row names.

```{r HUGO as row names}
# Set the HUGO symbols as rownames and remove the previous column of HUGO symbol
rownames(aggregatedData) <- aggregatedData$hgnc_symbol
aggregatedData$hgnc_symbol <- NULL
```

```{r combinedInfo as col names}
# Now to apply combinedInfo as column names in aggregatedData
names(aggregatedData) <- metadataDf$combinedInfo
names(aggregatedData)

# Convert to a data frame
aggregatedDataDf <- as.data.frame(aggregatedData)

# Write the normalized CPM to a CSV file
write.csv(aggregatedDataDf, file="a1AggregatedDataDf.csv", row.names=TRUE)
```

### 3.2 Pre-normalization Plots

```{r pre norm box}
# Convert it to DGEList
dge <- DGEList(counts=aggregatedData)

# Compute CPM and add a pseudocount of for numerical stability
cpmDataPre <- edgeR::cpm(dge, log = TRUE, prior.count = 1)

# Plot the box plot
graphics::boxplot(cpmDataPre, xlab = "Samples", ylab = "log2 CPM",
 las = 2, cex = 0.5, cex.lab = 0.5,
 cex.axis = 0.5, main = "Pre-normalization Box Plot")

# Draw the median on each box plot
abline(h = median(apply(cpmDataPre, 2, median)),
 col = "red", lwd = 0.6, lty = "dashed")
```

We can see that the data is heavily skewed
towards higher values when log-transformed.
It is because most genes have low read counts
and a few have very high read counts. I added
a pseudocount of 1 before log transformation,
ensuring that there are no log-transformed
values of negative infinity, which would
result from taking the log of zero. The
presence of data points below zero suggests
that there are some expression values that
are, on a CPM basis, less than 1. This is
entirely possible, especially for lowly
expressed genes.

```{r pre norm dens}
# Calculate the density for each sample and plot it
plot(NULL, xlim = range(cpmDataPre), 
     ylim = c(0, max(sapply(1:ncol(cpmDataPre), function(i) {
  max(density(cpmDataPre[, i])$y)
}))), 
xlab = "log2 CPM", ylab = "Smoothed Density", 
main = "Pre-normalization Smoothing Density Plot")

# Add a color palette
colors <- rainbow(ncol(cpmDataPre))

# Plot the density for each sample
for (i in 1:ncol(cpmDataPre)) {
  dens <- density(cpmDataPre[, i])
  lines(dens, col = colors[i], lwd = 2)
}

# Add a legend to identify the samples
legend("topright", legend = colnames(cpmDataPre), cex=0.7, col = colors, 
       bg = "gray95", lwd = 2)
```

We can see that the curves are almost
identical to each other, which implied that
this dataset has possibly undergone some
normalization process before it is submitted.
Nonetheless, we will still apply
normalization to see if there is a
difference.

### 3.3 TMM Normalization

I chose TMM normalization for this dataset
due to the following benefits:

1.  **Effectiveness in handling compositional
    differences** between samples.

2.  **Robustness against outliers**, ensuring
    stability in diverse datasets.

3.  **Computational efficiency**,
    facilitating its use in large-scale
    studies.

These factors make TMM a suitable choice for
accurately comparing gene expression across
different conditions, essential in research
exploring complex biological phenomena like
sex-dependent differences in disease.

```{r TMM norm}
# Calculate normalization factors, by default it uses the TMM method
dge <- edgeR::calcNormFactors(dge)

# Get normalized counts
normCounts <- 
  dge$counts / dge$samples$norm.factors * mean(dge$samples$lib.size)

# Calculate CPM with edgeR and log2-transform the data
cpmDataPost <- edgeR::cpm(dge, log = TRUE, prior.count = 1)
```

```{r Convert to df and same}
# Convert to a data frame
normalizedCpmDf <- as.data.frame(cpmDataPost)

# Write the normalized CPM to a CSV file
write.csv(normalizedCpmDf, file="a1NormalizedCpmDf.csv", row.names=TRUE)

```

### 3.4 Post-normalization Plots

```{r post norm box}
# Plot the box plot
graphics::boxplot(cpmDataPost, xlab = "Samples", ylab = "log2 CPM",
 las = 2, cex = 0.5, cex.lab = 0.5,
 cex.axis = 0.5, main = "Post-normalization Box Plot")

# draw the median on each box plot
abline(h = median(apply(cpmDataPost, 2, median)),
 col = "red", lwd = 0.6, lty = "dashed")
```

Even though the box plot is very similar to
the one before normalization, it has become
more unanimous in height and median values.

```{r post norm dens}
# Calculate the density for each sample and plot it
plot(NULL, xlim = range(cpmDataPost), 
     ylim = c(0, max(sapply(1:ncol(cpmDataPost), function(i) {
  max(density(cpmDataPost[, i])$y)
}))), 
xlab = "log2 CPM", ylab = "Smoothed Density", 
main = "Post-normalization Smoothing Density Plot")

# Add a color palette
colors <- rainbow(ncol(cpmDataPost))

# Plot the density for each sample
for (i in 1:ncol(cpmDataPost)) {
  dens <- density(cpmDataPost[, i])
  lines(dens, col = colors[i], lwd = 2)
}

# Add a legend to identify the samples
legend("topright", legend = colnames(cpmDataPost), cex=0.7, col = colors, 
       bg = "gray95", lwd = 2)
```

Even though the density plot is very similar
to the one before normalization, the curves
become more overlapped. This implies that our
normalization still works, even though it
only improves the data by a little.

## 4. Discussion and Interpretation

### 4.1 MDS Plot

An MDS (Multidimensional scaling) plot is
used to visualize the level of similarity of
individual cases of a dataset. In our case,
we can use it to show how similar or
dissimilar the samples are from each other.

```{r mds plot}
# Extract the group information from the row names
# The pattern looks for "Ctrl" or "PD" followed by "_M" or "_F"
# and assigns to the corresponding parts of the group factor
dge$samples$group <- 
  factor(gsub(".*(Ctrl|PD)_(M|F).*", "\\1_\\2", rownames(dge$samples)))

# First, you need to estimate the dispersions
dge <- edgeR::estimateDisp(dge, design = model.matrix(~1, data=dge$samples))

# Capture the output and use plot function
mdsData <- limma::plotMDS(dge, plot = FALSE)

# Plot the MDS data
plot(mdsData$x, mdsData$y, 
     xlab = "Dimension 1", 
     ylab = "Dimension 2", 
     main = "MDS Plot",
     col = as.factor(dge$samples$group),
     pch = 16)

# Add a legend if necessary
legend("topright", legend=levels(as.factor(dge$samples$group)), 
       col=1:length(levels(as.factor(dge$samples$group))), 
       pch=16)
```

We can see that PD points are more clustered
together in the upper left corner, whereas
the points in control group are more
scattered in the middle part. We can also see
that PD_F and PD_M are closely placed,
suggesting there are sex-dependent
differences in gene expression levels in PD.

### 4.2 Mean Variance Plot

We will now use a mean-variance plot to
visualize the relationship between the mean
of normalized counts and the variance.

```{r mean var plot}
# Estimate the mean-variance relationship
dge <- estimateDisp(dge, design = model.matrix(~group, data=dge$samples))

# Plot the mean-variance relationship
plotMeanVar(dge, show.tagwise.vars=TRUE, NBline=TRUE, main="Mean-Variance Plot")

# 'show.tagwise.vars=TRUE' adds points to the plot for each tag (gene) showing the tagwise variance.
# 'NBline=TRUE' adds the expected negative binomial mean-variance relationship to the plot.

```

-   **X-axis**: Represents the mean gene
    expression level on a log10 scale. Low
    expression genes are to the left, higher
    expression genes to the right.

-   **Y-axis**: Indicates the pooled
    gene-level variance on a log10 scale.
    Higher values signify more variance in
    gene expression across the samples.

-   **Blue Points**: Each represents a gene.
    Their distribution suggests the trend
    that as gene expression increases, so
    does variance, which is a common
    characteristic in RNA-seq data.

-   **Black Line**: This is likely the fitted
    line or model representing the expected
    mean-variance relationship in the
    dataset.

-   **Red X**: These are outliers or genes
    with variance that is significantly
    higher than what the model predicts.

-   **Red Crosses**: Additional outliers or
    notable points of interest that deviate
    from the expected variance, though the
    specific meaning would depend on the
    context provided by the study.

We can see that the overall trend is that
variance increases with the mean. It is most
likely the gene expression follows Poisson or
negative binomial distributions. The presence
of outliers or points of interest marked in
red suggests there are genes whose variance
is not well explained by the mean alone,
which could be due to biological variability
or technical artifacts. These would be
candidates for further investigation.

### 4.3 Dispersion Plot

We will now use a dispersion plot to assess
the variability of gene expression data.

```{r disp plot}
# Estimate common dispersion
dge <- edgeR::estimateCommonDisp(dge, verbose=TRUE)

# Estimate tagwise dispersion
dge <- edgeR::estimateTagwiseDisp(dge)

# Create a plot of the estimated dispersions
plotBCV(dge)
```

-   Most genes cluster around the trend line,
    indicating that their variability is as
    expected for their expression level.

-   The common dispersion line is close to
    the trend line, suggesting that the
    variability in expression is constant
    across genes.

### 4.4 Assignment Questions

**Why is the dataset of interest to you?**

This study explores the sex-dependent
differences in gene expression related to PD,
which is a significant area of research. I am
interested in Parkinson's disease because
there are currently no effective cure and it
is complex given its chronic nature.
Biological sex has been reported to influence
the symptom profile of PD, with differences
in disease incidence and symptom
manifestation between males and females, and
I am curious how it manifests itself
defferently between male and female. I heard
that biased data used for medicine
development could cause underrepresented
groups to benefit less from these medicines.
Understanding these differences at a
molecular level could have important
implications for personalized medicine
approaches to treating and managing PD.

**What are the control and test conditions of
the dataset?**

Control Condition: Samples from individuals
without Parkinson's disease.

Test Condition: Samples from individuals
diagnosed with Parkinson's disease.

Additionally, the differential expression
analyses were performed separately on
datasets using only female or male samples to
identify transcripts that display significant
sex-dependent differences between Parkinson's
disease patients and controls.

**How many samples in each of the conditions
of your dataset?**

There are 16 samples in total. 8 are
non-demented controls, and the other 8 are
patients with Parkinson's. Among the 16
samples, 10 are male and 6 are females.

|        | Ctrl | PD  |
|--------|------|-----|
| Male   | 5    | 5   |
| Female | 3    | 3   |

**Were there expression values that were not
unique for specific genes? How did you handle
these?**

According to the study [@Tranchevent2023],
the authors already addressed the issue of
non-unique expression values by selecting the
probe or transcript with the highest average
expression across the datasets for inclusion
in the meta-analysis. This approach was
chosen because probes or transcripts with low
signal are generally associated with lower
reliability.

**Were there expression values that could not
be mapped to current HUGO symbols?**

There are 19716 ENSEMBL IDs that could not be
mapped to current HUGO symbols.

**Were there any outliers in your dataset?
How were they handled in the originating
paper? How many outliers were removed?**

As the data uploaded to NCBI is already
preprocessed, there are few outliers in my
dataset, I double checked the dataset for
missing and negative values and there were
none. I decided to

In the original paper, outliers were
identified and handled as part of the quality
control process before raw data
preprocessing. This was done using the R
package ArrayQualityMetrics. The package
employs three main methods for sample outlier
detection. Any sample flagged as an outlier
in at least two out of the three checks was
removed from the analysis. According to this
approach, a total of four samples across
three datasets were identified as outliers
and subsequently removed based on these
standard filtering criteria.

**How did you handle replicates?**

According to the study [@Tranchevent2023],
the dataset has preprocessed in some ways.
The authors handled duplicates or multiple
probes/transcripts for the same gene by
aggregating or selecting data to ensure
specificity and relevance for their
differential expression analyses. Here's how
they approached it:

Removing Irrelevant Probes/Transcripts:
Before the differential expression analyses,
probes and transcripts were cleaned to focus
only on relevant entities. This step was
crucial for probes, as transcripts are
generally well-defined and associated with a
single gene. First, probes associated with
five or more genes were discarded to maintain
focus on signals that are specific enough for
straightforward interpretation. Second,
probes that matched more than one gene were
also discarded if there was another probe
that matched a subset of these genes. For
example, a probe matching both gene A and
gene B was removed if another probe existed
that matched only gene A or only gene B.
Complex cases where probes matched
overlapping sets of genes were removed
because their interpretation would have been
challenging. For instance, if two probes
matched genes A+B and genes A+C,
respectively, they were removed, regardless
of the existence of probes matching only gene
A, only gene B, or only gene C.

Building on top of it, I aggregated
replicates when setting the row names to be
HUGO symbols by summing them.

I chose to sum the duplicates because it:

-   Strengthens Signal: Enhances detection of
    genes, especially those with low
    expression.
-   Reduces Variability: Balances technical
    differences across probes or reads.
-   Simplifies Data: Makes downstream
    analysis more straightforward by
    representing each gene with a single
    value.
-   Improves Reproducibility: Standardizes
    data handling, promoting consistent
    results across studies.
-   Uses All Data: Ensures no valuable
    information is lost, leveraging the full
    dataset for analysis.

**What is the final coverage of your
dataset?**

The final dataset coverage is 28904 genes
with 16 samples.

## 5. References

```{r cite R package, include=FALSE}
cite_packages(out.dir = ".")
```
